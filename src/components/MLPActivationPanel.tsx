import NeuronCell from "./NeuronCell";
import Term from "./Term";

interface Props {
  mlpHidden: number[];
  mlpActiveMask: boolean[];
}

export default function MLPActivationPanel({
  mlpHidden,
  mlpActiveMask,
}: Props) {
  return (
    <div className="panel">
      <div className="panel-title">
        Couche cach√©e <Term id="mlp" /> (64 <Term id="neurone" />
        s)
      </div>
      <div className="explain">
        Apr√®s la couche lin√©aire qui expanse de 16 ‚Üí 64 <Term id="dimension" />
        s, l'activation{" "}
        <b>
          <Term id="relu" />
        </b>{" "}
        met toutes les valeurs n√©gatives √† z√©ro. Seuls les <Term id="neurone" />
        s ¬´ actifs ¬ª (verts) laissent passer l'information. C'est ainsi que le
        mod√®le cr√©e des repr√©sentations non lin√©aires.
      </div>
      <div className="neuron-grid">
        {mlpHidden.map((v, i) => (
          <NeuronCell key={i} value={v} index={i} />
        ))}
      </div>
      <div className="label-dim mt-4">
        {mlpActiveMask.filter(Boolean).length} / 64 <Term id="neurone" />s
        actifs apr√®s <Term id="relu" />
      </div>
      <div className="explain" style={{ marginTop: 8 }}>
        üí° Ici le MLP transforme un seul token isol√©. √Ä l'
        <b>√©tape 4 ‚Äî Attention</b>, tu verras comment l'attention m√©lange
        d'abord l'information de plusieurs tokens ‚Äî le MLP travaille alors sur
        un vecteur bien plus riche.
      </div>
    </div>
  );
}
